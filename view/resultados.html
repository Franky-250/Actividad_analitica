<section id="resultados">
    <div class="resultados-container">
      <h2>Resultados</h2>
      <p>
        Los resultados obtenidos en esta actividad reflejan la efectividad de la metodología aplicada en el scraping, así como en la implementación del flujo de trabajo colaborativo en GitHub. Se logró extraer información detallada de productos en Mercado Libre, específicamente de calzado deportivo masculino de la marca Nike, incluyendo el nombre de cada producto y su precio, de forma exitosa y sin interrupciones técnicas.
      </p>
      <p>
        Además, los datos extraídos se organizaron y almacenaron en formatos accesibles para diferentes propósitos:
      </p>
      <ul>
        <li><strong>Archivo CSV:</strong> Este formato facilitó el análisis estructurado en herramientas como pandas o Excel, proporcionando una tabla clara y organizada de productos y precios.</li>
        <li><strong>Archivo JSON:</strong> Este formato fue útil para integraciones con aplicaciones web o proyectos que requieren datos estructurados en un lenguaje de programación.</li>
        <li><strong>Archivo HTML:</strong> Generamos un archivo que presenta la información de manera visual y ordenada, simulando un catálogo de productos en línea que destaca los títulos y precios de los productos.</li>
      </ul>
      <p>
        En esta actividad, los colaboradores también agregaron nuevas funcionalidades mediante gráficos:
      </p>
      <ul>
        <li>Un gráfico de barras que muestra los 10 productos más caros, permitiendo identificar de manera rápida las tendencias en los precios.</li>
        <li>Un gráfico de torta que representa la distribución porcentual de los precios de estos 10 productos, proporcionando una perspectiva visual sobre cómo se dividen los costos.</li>
        <li>Procesamiento de datos en un DataFrame de pandas para facilitar su manejo y análisis tabular.</li>
      </ul>
      <p>
        Por último, el uso de GitHub Actions permitió implementar un pipeline de CI/CD que automatizó la validación del código y garantizó que las modificaciones realizadas por los colaboradores fueran seguras antes de fusionarlas. Este proceso optimizó la calidad y consistencia del proyecto final.
      </p>
      <p>
        En general, los resultados obtenidos no solo validan la estrategia utilizada, sino que también resaltan la importancia de la colaboración y las herramientas modernas en el desarrollo de software, logrando un producto completo y profesional.
      </p>
  
      <h2>Conclusiones</h2>
      <p>
        Esta actividad permitió consolidar conocimientos sobre scraping web y la importancia de la colaboración en proyectos de desarrollo. Utilizando BeautifulSoup como herramienta principal, logramos extraer datos clave de Mercado Libre, como títulos y precios de productos, demostrando que es una opción eficiente para sitios con HTML estático.
      </p>
      <p>
        Configurar adecuadamente los headers y añadir pausas entre las solicitudes fueron pasos esenciales para evitar bloqueos y garantizar un scraping fluido. Al almacenar los datos en múltiples formatos como CSV, JSON y HTML, se facilitó su análisis y reutilización en diferentes plataformas, mientras que las visualizaciones generadas en gráficos de barras y torta hicieron más intuitiva la interpretación de los resultados.
      </p>
      <p>
        El uso de GitHub y GitHub Actions fue clave para el flujo de trabajo colaborativo, asegurando la calidad del código a través de pruebas automatizadas y facilitando la integración continua. Esto no solo mejoró la organización del equipo, sino que también optimizó la eficiencia y la gestión del proyecto.
      </p>
      <p>
        En resumen, esta experiencia fue altamente enriquecedora, proporcionando una base sólida en técnicas de scraping, manejo de datos y prácticas de colaboración en desarrollo de software, además de aportar un enfoque práctico y profesional para futuros proyectos.
      </p>
    </div>
  </section>
  